#!/usr/bin/env python3
"""
Bitget çˆ¬è™«æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯çˆ¬è™«åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import asyncio
import json
import sys
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from crawler import BitgetCrawler


async def test_schema_loading():
    """æµ‹è¯• schema åŠ è½½"""
    print("ğŸ§ª æµ‹è¯• schema åŠ è½½...")
    try:
        crawler = BitgetCrawler()
        schema = crawler.schema
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['title', 'description', 'http_path', 'next_page', 'content']
        schema_fields = [field['name'] for field in schema.get('fields', [])]
        
        missing_fields = [field for field in required_fields if field not in schema_fields]
        
        if missing_fields:
            print(f"âŒ Schema ç¼ºå°‘å­—æ®µ: {missing_fields}")
            return False
        else:
            print(f"âœ… Schema åŠ è½½æˆåŠŸï¼ŒåŒ…å«å­—æ®µ: {schema_fields}")
            return True
            
    except Exception as e:
        print(f"âŒ Schema åŠ è½½å¤±è´¥: {e}")
        return False


async def test_single_page_extraction():
    """æµ‹è¯•å•é¡µé¢æå–"""
    print("ğŸ§ª æµ‹è¯•å•é¡µé¢æ•°æ®æå–...")
    try:
        crawler = BitgetCrawler()
        
        # æµ‹è¯•æå–å•ä¸ªé¡µé¢
        from crawl4ai import AsyncWebCrawler
        async with AsyncWebCrawler(verbose=True) as web_crawler:
            page_data = await crawler.extract_page_data(web_crawler, crawler.start_url)
            
        if page_data:
            print("âœ… å•é¡µé¢æå–æˆåŠŸ")
            print(f"   æ ‡é¢˜: {page_data.get('title', 'N/A')[:50]}...")
            print(f"   æè¿°: {page_data.get('description', 'N/A')[:50]}...")
            print(f"   HTTPè·¯å¾„: {page_data.get('http_path', 'N/A')[:50]}...")
            print(f"   ä¸‹ä¸€é¡µ: {page_data.get('next_page', 'N/A')[:50]}...")
            print(f"   å†…å®¹é•¿åº¦: {len(page_data.get('content', ''))}")
            return True
        else:
            print("âŒ å•é¡µé¢æå–å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ å•é¡µé¢æå–å¼‚å¸¸: {e}")
        return False


async def test_markdown_conversion():
    """æµ‹è¯• Markdown è½¬æ¢"""
    print("ğŸ§ª æµ‹è¯• Markdown è½¬æ¢...")
    try:
        crawler = BitgetCrawler()
        
        # æµ‹è¯• HTML è½¬ Markdown
        test_html = """
        <h1>æµ‹è¯•æ ‡é¢˜</h1>
        <p>è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ®µè½ã€‚</p>
        <ul>
            <li>åˆ—è¡¨é¡¹ 1</li>
            <li>åˆ—è¡¨é¡¹ 2</li>
        </ul>
        <code>ä»£ç ç¤ºä¾‹</code>
        """
        
        markdown_result = crawler.html_to_markdown(test_html)
        
        if markdown_result and "# æµ‹è¯•æ ‡é¢˜" in markdown_result:
            print("âœ… Markdown è½¬æ¢æˆåŠŸ")
            print(f"   è½¬æ¢ç»“æœ: {markdown_result[:100]}...")
            return True
        else:
            print("âŒ Markdown è½¬æ¢å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ Markdown è½¬æ¢å¼‚å¸¸: {e}")
        return False


async def test_url_normalization():
    """æµ‹è¯• URL æ ‡å‡†åŒ–"""
    print("ğŸ§ª æµ‹è¯• URL æ ‡å‡†åŒ–...")
    try:
        crawler = BitgetCrawler()
        
        # æµ‹è¯•å„ç§ URL æ ¼å¼
        test_cases = [
            ("/zh-CN/api-doc/uta/account", "https://www.bitget.com/zh-CN/api-doc/uta/account"),
            ("https://www.bitget.com/zh-CN/api-doc/uta/trade", "https://www.bitget.com/zh-CN/api-doc/uta/trade"),
            ("../intro", "https://www.bitget.com/intro"),
        ]
        
        all_passed = True
        for input_url, expected in test_cases:
            result = crawler.normalize_url(input_url, crawler.base_url)
            if result != expected:
                print(f"âŒ URL æ ‡å‡†åŒ–å¤±è´¥: {input_url} -> {result} (æœŸæœ›: {expected})")
                all_passed = False
            else:
                print(f"âœ… URL æ ‡å‡†åŒ–æˆåŠŸ: {input_url} -> {result}")
                
        return all_passed
        
    except Exception as e:
        print(f"âŒ URL æ ‡å‡†åŒ–å¼‚å¸¸: {e}")
        return False


async def test_data_cleaning():
    """æµ‹è¯•æ•°æ®æ¸…ç†"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®æ¸…ç†...")
    try:
        crawler = BitgetCrawler()
        
        # æµ‹è¯•æ•°æ®æ¸…ç†
        test_data = {
            "title": "  æµ‹è¯•æ ‡é¢˜  \n\n  ",
            "description": ["", "  æœ‰æ•ˆæè¿°  ", ""],
            "content": "  å¤šä¸ª    ç©ºæ ¼   çš„   æ–‡æœ¬  ",
            "empty_field": "",
            "none_field": None
        }
        
        cleaned_data = crawler.clean_extracted_data(test_data)
        
        expected = {
            "title": "æµ‹è¯•æ ‡é¢˜",
            "description": "æœ‰æ•ˆæè¿°",
            "content": "å¤šä¸ª ç©ºæ ¼ çš„ æ–‡æœ¬",
            "empty_field": "",
            "none_field": ""
        }
        
        if cleaned_data == expected:
            print("âœ… æ•°æ®æ¸…ç†æˆåŠŸ")
            return True
        else:
            print(f"âŒ æ•°æ®æ¸…ç†å¤±è´¥")
            print(f"   æœŸæœ›: {expected}")
            print(f"   å®é™…: {cleaned_data}")
            return False
            
    except Exception as e:
        print(f"âŒ æ•°æ®æ¸…ç†å¼‚å¸¸: {e}")
        return False


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹è¿è¡Œ Bitget çˆ¬è™«æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("Schema åŠ è½½", test_schema_loading),
        ("Markdown è½¬æ¢", test_markdown_conversion),
        ("URL æ ‡å‡†åŒ–", test_url_normalization),
        ("æ•°æ®æ¸…ç†", test_data_cleaning),
        ("å•é¡µé¢æå–", test_single_page_extraction),  # æœ€åæµ‹è¯•ï¼Œéœ€è¦ç½‘ç»œ
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ {test_name}")
        print("-" * 30)
        try:
            if await test_func():
                passed += 1
            else:
                print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼çˆ¬è™«åŠŸèƒ½æ­£å¸¸")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return False


async def main():
    """ä¸»å‡½æ•°"""
    success = await run_all_tests()
    
    if success:
        print("\nâœ… æµ‹è¯•å®Œæˆï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨çˆ¬è™«:")
        print("   python run.py --dry-run    # è¯•è¿è¡Œ")
        print("   python run.py              # å®Œæ•´çˆ¬å–")
        sys.exit(0)
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())